{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251855b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import regex as re\n",
    "import concurrent.futures\n",
    "import time\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "# File paths relative to .exe location\n",
    "WEBPATH_FILE =  \"webpath2.txt\"\n",
    "FREQUENCY_FILE =  \"frequency.txt\"\n",
    "RESULT_FILE =  \"scraperesult.csv\"\n",
    "FAULTY_FILE =  \"faultypath.txt\"\n",
    "\n",
    "try:\n",
    "    with open(WEBPATH_FILE, \"r\") as file:\n",
    "        webpath = file.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {WEBPATH_FILE} not found. Created an empty file. Please add URLs to scrape.\" ) \n",
    "    with open(WEBPATH_FILE, \"w\") as file:\n",
    "        file.write(\"\")\n",
    "\n",
    "    webpath = []\n",
    "\n",
    "# Some global constants for scraping\n",
    "# such as headers, name and price patterns, \n",
    "# and return values for not found cases\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 11.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.6998.166 Safari/537.36\"}\n",
    "PATTERNS = {\n",
    "    \"bunnings\": [\n",
    "        re.compile(r\"MuiTypography-root sc-500f213-2 .* MuiTypography-h1\"), \n",
    "        \"sc-bbcf7fe4-3 kAMCuk\"\n",
    "    ],\n",
    "    \"jbhifi\": [\n",
    "        re.compile(r\"_12mtftw9\"),  # Name pattern\n",
    "        \"PriceTag_actualWrapperDefault__1eb7mu915\"  # Updated price pattern\n",
    "    ]\n",
    "}\n",
    "NOTFOUND = \"N/A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0f51bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the website name from the URL\n",
    "def get_website_name(url):\n",
    "    \"\"\"Extract website name from URL using regex.\"\"\"\n",
    "    pattern = r'https?://(?:www\\.)?([^.]+)'\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else NOTFOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f8184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bunnings\n",
      "bunnings\n",
      "bunnings\n",
      "bunnings\n",
      "bunnings\n",
      "jbhifi\n",
      "jbhifi\n",
      "jbhifi\n",
      "jbhifi\n",
      "jbhifi\n"
     ]
    }
   ],
   "source": [
    "for line in webpath:\n",
    "    print(get_website_name(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3348c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_with_selenium(url, patterns):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')  # Added for better performance\n",
    "    options.add_argument('--disable-extensions')  # Disable extensions\n",
    "    options.add_argument('--disable-images')  # Don't load images\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    NAMEPATTERN, PRICEPATTERN = patterns\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        driver.set_page_load_timeout(20)\n",
    "        # Use explicit wait with timeout\n",
    "        wait = WebDriverWait(driver, 20)  # 5 second timeout\n",
    "        \n",
    "        # Wait for price element with explicit condition\n",
    "        price_element = wait.until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, PRICEPATTERN))\n",
    "        )\n",
    "        \n",
    "        price_text = \"\".join(price_element.text.split())\n",
    "        \n",
    "        # Get product name with explicit wait\n",
    "        try:\n",
    "            name_element = driver.find_element(By.TAG_NAME, 'h1')\n",
    "            name_text = name_element.text\n",
    "        except:\n",
    "            name_text = NOTFOUND\n",
    "            \n",
    "        return (name_text, price_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return (NOTFOUND, NOTFOUND)\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2183117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_requests(url, patterns):\n",
    "    \n",
    "    NAMEPATTERN, PRICEPATTERN = patterns\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)    \n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = bs(response.content, \"html.parser\")\n",
    "            name = soup.find(\"h1\", class_=NAMEPATTERN) # Get the product name\n",
    "            price = soup.find(\"p\", class_=PRICEPATTERN) # Get the price tag\n",
    "\n",
    "            name = name.text.strip() if name else NOTFOUND\n",
    "            price = price.text.strip() if price else NOTFOUND\n",
    "            \n",
    "        else:\n",
    "            name = price = NOTFOUND\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        name = price = NOTFOUND\n",
    "\n",
    "    return (name, price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a282324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_url(url):\n",
    "    url = url.strip()\n",
    "    website_name = get_website_name(url)\n",
    "    patterns = PATTERNS.get(website_name, (NOTFOUND, NOTFOUND))\n",
    "\n",
    "    try:\n",
    "        name, price = scrape_requests(url, patterns)\n",
    "        if name == NOTFOUND or price == NOTFOUND:\n",
    "            name, price = scrape_with_selenium(url, patterns)\n",
    "        \n",
    "        print(url, name, price)\n",
    "        return (url, name, price)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return (url, NOTFOUND, NOTFOUND)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a11862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paralle_scrape(webpath, max_workers=5):\n",
    "\n",
    "    # I don't really understand how parallel process works\n",
    "    # so this is just a copy past from the internet\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(scrape_single_url, webpath))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93cdca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bunnings.com.au/200-x-50mm-2-4m-treated-pine-sleeper-h4_p8032702 200 x 50mm 2.4m Treated Pine Sleeper H4 $18\n",
      "https://www.bunnings.com.au/estilo-chrome-3-function-hand-shower-connector-set-wels-3-star-rated-9l-min_p5002610 Estilo Chrome 3 Function Hand Shower & Connector Set WELS 3 Star Rated 9L/min $31.97\n",
      "https://www.bunnings.com.au/ozito-1800w-2030psi-high-pressure-washer_p0254158 Ozito 1800W 2030PSI High Pressure Washer $99\n",
      "https://www.bunnings.com.au/dulux-4l-interior-paint-wash-wear-plus-kitchen-bathroom-low-sheen-vivid-white-4l_p1370128 Dulux 4L Interior Paint Wash&Wear +PLUS Kitchen & Bathroom Low Sheen Vivid White - 4L $125.50\n",
      "https://www.jbhifi.com.au/products/alogic-ultra-mini-usb-c-to-usb-a-adapter-space-grey ALOGIC Ultra Mini USB-C to USB-A Adapter (Space Grey) $15\n",
      "https://www.jbhifi.com.au/products/apple-macbook-pro-14-inch-with-m4-pro-chip-512gb-24gb-space-black2024 Apple MacBook Pro 14-inch with M4 Pro Chip, 512GB/24GB (Space Black)[2024] $3127\n",
      "https://www.jbhifi.com.au/products/samsung-77-s90f-oled-4k-smart-ai-tv-2025 Samsung 77\" S90F OLED 4K Smart AI TV [2025] $3795\n",
      "https://www.jbhifi.com.au/products/samsung-65-s90f-oled-4k-smart-ai-tv-2025 Samsung 65\" S90F OLED 4K Smart AI TV [2025] $2995\n",
      "https://www.bunnings.com.au/dulux-1step-prep-primer-sealer-undercoat-4l-4l_ N/A N/A\n",
      "https://www.jbhifi.com.au/products/samsung-75-qn70f-neo-qled-4k-mini-led-smart-ai-tv-2025 Samsung 75\" QN70F NEO QLED 4K Mini LED Smart AI TV [2025] $1995\n",
      "('https://www.bunnings.com.au/dulux-1step-prep-primer-sealer-undercoat-4l-4l_', 'N/A', 'N/A')\n",
      "('https://www.bunnings.com.au/dulux-4l-interior-paint-wash-wear-plus-kitchen-bathroom-low-sheen-vivid-white-4l_p1370128', 'Dulux 4L Interior Paint Wash&Wear +PLUS Kitchen & Bathroom Low Sheen Vivid White - 4L', '$125.50')\n",
      "('https://www.bunnings.com.au/200-x-50mm-2-4m-treated-pine-sleeper-h4_p8032702', '200 x 50mm 2.4m Treated Pine Sleeper H4', '$18')\n",
      "('https://www.bunnings.com.au/ozito-1800w-2030psi-high-pressure-washer_p0254158', 'Ozito 1800W 2030PSI High Pressure Washer', '$99')\n",
      "('https://www.bunnings.com.au/estilo-chrome-3-function-hand-shower-connector-set-wels-3-star-rated-9l-min_p5002610', 'Estilo Chrome 3 Function Hand Shower & Connector Set WELS 3 Star Rated 9L/min', '$31.97')\n",
      "('https://www.jbhifi.com.au/products/apple-macbook-pro-14-inch-with-m4-pro-chip-512gb-24gb-space-black2024', 'Apple MacBook Pro 14-inch with M4 Pro Chip, 512GB/24GB (Space Black)[2024]', '$3127')\n",
      "('https://www.jbhifi.com.au/products/alogic-ultra-mini-usb-c-to-usb-a-adapter-space-grey', 'ALOGIC Ultra Mini USB-C to USB-A Adapter (Space Grey)', '$15')\n",
      "('https://www.jbhifi.com.au/products/samsung-77-s90f-oled-4k-smart-ai-tv-2025', 'Samsung 77\" S90F OLED 4K Smart AI TV [2025]', '$3795')\n",
      "('https://www.jbhifi.com.au/products/samsung-65-s90f-oled-4k-smart-ai-tv-2025', 'Samsung 65\" S90F OLED 4K Smart AI TV [2025]', '$2995')\n",
      "('https://www.jbhifi.com.au/products/samsung-75-qn70f-neo-qled-4k-mini-led-smart-ai-tv-2025', 'Samsung 75\" QN70F NEO QLED 4K Mini LED Smart AI TV [2025]', '$1995')\n"
     ]
    }
   ],
   "source": [
    "results = paralle_scrape(webpath, max_workers=5)\n",
    "for line in results:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce861abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(file):\n",
    "    try:\n",
    "        with open(file, \"r\") as csv_file:\n",
    "            csv_file = csv.reader(csv_file)\n",
    "            data = {}\n",
    "\n",
    "            try:\n",
    "                headers = next(csv_file)  # Read the header line\n",
    "            except StopIteration:\n",
    "                # If the file is empty, create headers\n",
    "                headers = [\"Name\", \"Link\", \"Lowest Price\", \"Start Date\", \"End Date\", \"Today Price\"]\n",
    "                return headers, data\n",
    "            \n",
    "            for line in list(csv_file)[1:]:\n",
    "                if len(line) == 6:\n",
    "                    data[line[0]] = {key: value for \n",
    "                                    key, value in zip(headers[1:], \n",
    "                                                    line[1:])}\n",
    "        return headers, data\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # Create empty CSV with headers\n",
    "        headers = [\"Name\", \"Link\", \"Lowest Price\", \"Start Date\", \"End Date\", \"Today Price\"]\n",
    "        with open(file, \"w\", newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(headers)\n",
    "        return headers, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7330c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_item_entry(name, path, price, today_date):\n",
    "    \"\"\"Create entry for a new item not in old data.\"\"\"\n",
    "    return (name, path, price, today_date, today_date, price)\n",
    "\n",
    "def create_lower_price_entry(name, path, new_price, today_date):\n",
    "    \"\"\"Create entry when new price is lower than old price.\"\"\"\n",
    "    return (name, path, new_price, today_date, today_date, new_price)\n",
    "\n",
    "def create_same_price_entry(name, path, price, old_item, today_date):\n",
    "    \"\"\"Create entry when price hasn't changed - extend the date range.\"\"\"\n",
    "    return (name, path, price, \n",
    "            old_item.get(\"Start Date\", today_date), \n",
    "            today_date, \n",
    "            price)\n",
    "\n",
    "def create_higher_price_entry(name, path, old_item, new_price):\n",
    "    \"\"\"Create entry when new price is higher - keep old lowest price.\"\"\"\n",
    "    old_price = old_item[\"price\"]\n",
    "    return (name, path, old_price, \n",
    "            old_item.get(\"Start Date\", \"\"), \n",
    "            old_item.get(\"End Date\", \"\"), \n",
    "            new_price)\n",
    "\n",
    "def single_item_comparison(path, name, price, old_scrape, today_date):\n",
    "    \"\"\"Process a single scraped item and return the appropriate entry.\"\"\"\n",
    "    if name == NOTFOUND or price == NOTFOUND:\n",
    "        return path\n",
    "        \n",
    "    curr_price = float(price.replace(\"$\", \"\"))\n",
    "    \n",
    "    # New item - not in old data\n",
    "    if name not in old_scrape:\n",
    "        return create_new_item_entry(name, path, price, today_date)\n",
    "    \n",
    "    # Existing item - compare prices\n",
    "    old_item = old_scrape[name]\n",
    "    old_price = float(old_item[\"Lowest Price\"].replace(\"$\", \"\"))\n",
    "    \n",
    "    if curr_price < old_price:\n",
    "        return create_lower_price_entry(name, path, price, today_date)\n",
    "    elif curr_price == old_price:\n",
    "        return create_same_price_entry(name, path, price, old_item, today_date)\n",
    "    else:\n",
    "        return create_higher_price_entry(name, path, old_item, price)\n",
    "\n",
    "def compareScrape_new_old(new_scrape, old_scrape):\n",
    "    \"\"\"Compare new scrape results with old data and create updated entries.\n",
    "    \n",
    "    Args:\n",
    "        new_scrape: List of (path, name, price) tuples from current scrape\n",
    "        old_scrape: Dictionary of existing item data\n",
    "        \n",
    "    Returns:\n",
    "        List of processed entries ready for CSV writing\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    faulty_links = []\n",
    "    today_date = time.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    for path, name, price in new_scrape:\n",
    "        entry = single_item_comparison(path, name, price, old_scrape, today_date)\n",
    "        if entry == path:\n",
    "            faulty_links.append(path)\n",
    "              # Only add valid entries\n",
    "        elif entry:\n",
    "            data.append(entry)\n",
    "            \n",
    "    return data, faulty_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3fc3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(file, headers, data):\n",
    "    with open(file, \"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bunnings.com.au/dulux-1step-prep-primer-sealer-undercoat-4l-4l_ N/A N/A\n",
      "https://www.bunnings.com.au/dulux-4l-interior-paint-wash-wear-plus-kitchen-bathroom-low-sheen-vivid-white-4l_p1370128 Dulux 4L Interior Paint Wash&Wear +PLUS Kitchen & Bathroom Low Sheen Vivid White - 4L $125.50\n",
      "https://www.bunnings.com.au/200-x-50mm-2-4m-treated-pine-sleeper-h4_p8032702 200 x 50mm 2.4m Treated Pine Sleeper H4 $18\n",
      "https://www.bunnings.com.au/ozito-1800w-2030psi-high-pressure-washer_p0254158 Ozito 1800W 2030PSI High Pressure Washer $99\n",
      "https://www.bunnings.com.au/estilo-chrome-3-function-hand-shower-connector-set-wels-3-star-rated-9l-min_p5002610 Estilo Chrome 3 Function Hand Shower & Connector Set WELS 3 Star Rated 9L/min $31.97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\socket.py:849\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    848\u001b[39m     sock.bind(source_address)\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mTimeoutError\u001b[39m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get the result for today\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m scrape_result = \u001b[43mparalle_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Read the old scrape result from CSV\u001b[39;00m\n\u001b[32m      5\u001b[39m headers, data = read_from_csv(RESULT_FILE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mparalle_scrape\u001b[39m\u001b[34m(webpath, max_workers)\u001b[39m\n\u001b[32m      5\u001b[39m results = []\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m webpath:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     result = \u001b[43mscrape_single_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     results.append(result)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mscrape_single_url\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      7\u001b[39m name, price = scrape_requests(url, patterns)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == NOTFOUND \u001b[38;5;129;01mor\u001b[39;00m price == NOTFOUND:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     name, price = \u001b[43mscrape_with_selenium\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(url, name, price)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (url, name, price)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mscrape_with_selenium\u001b[39m\u001b[34m(url, patterns)\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (NOTFOUND, NOTFOUND)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:224\u001b[39m, in \u001b[36mChromiumDriver.quit\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:152\u001b[39m, in \u001b[36mService.stop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process.poll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_remote_shutdown_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    154\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:137\u001b[39m, in \u001b[36mService.send_remote_shutdown_command\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m30\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    138\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    139\u001b[39m     sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:126\u001b[39m, in \u001b[36mService.is_connectable\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_connectable\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    124\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Establishes a socket connection to determine if the service running\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03m    on the port is accessible.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py:99\u001b[39m, in \u001b[36mis_connectable\u001b[39m\u001b[34m(port, host)\u001b[39m\n\u001b[32m     97\u001b[39m socket_ = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     socket_ = \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     result = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _is_connectable_exceptions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\miniconda\\envs\\scraper\\Lib\\socket.py:856\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m         \u001b[43mexceptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[32m    857\u001b[39m     exceptions.append(exc)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the old scrape result from CSV\n",
    "headers, data = read_from_csv(RESULT_FILE)\n",
    "\n",
    "new_data, faulty_links = compareScrape_new_old(results, data)\n",
    "\n",
    "write_to_csv(RESULT_FILE, headers, new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
